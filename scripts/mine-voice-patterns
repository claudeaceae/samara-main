#!/usr/bin/env python3
"""
Mine Voice Patterns

Extracts style-relevant patterns from recent episodes and reflections
to update voice-state.json for the dynamic voice system.

Focuses on:
- Claude's message style analysis (casing, punctuation, length)
- What gets positive reception in conversation flow
- Identity evolution from reflections

Usage:
    mine-voice-patterns [--days 7] [--dry-run]
"""
from __future__ import annotations

import argparse
import json
import re
from collections import Counter
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any

MIND_PATH = Path.home() / ".claude-mind"
VOICE_STATE_FILE = MIND_PATH / "state" / "voice-state.json"
EPISODES_DIR = MIND_PATH / "memory" / "episodes"
REFLECTIONS_DIR = MIND_PATH / "memory" / "reflections"


def load_voice_state() -> dict[str, Any]:
    """Load current voice state or create default."""
    if VOICE_STATE_FILE.exists():
        return json.loads(VOICE_STATE_FILE.read_text())

    return {
        "updated": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
        "long_cycle": {
            "recurring_themes": [],
            "current_preoccupations": [],
            "what_lands_well": [],
            "identity_notes": ""
        },
        "medium_cycle": {
            "e_patterns": {
                "explanation_style": "dense, terse, signal-over-noise",
                "humor_level": "dry",
                "riffing_texture": "intellectual play",
                "appreciates": ["directness", "honest appraisal"],
                "dislikes": ["sycophancy", "excessive hedging"]
            },
            "complementary_stance": ""
        },
        "short_cycle": {
            "time_of_day": None,
            "season": None,
            "calendar_density": None,
            "recent_mood": None,
            "recent_topics": []
        }
    }


def get_recent_files(directory: Path, days: int, extension: str = ".md") -> list[Path]:
    """Get files from the last N days."""
    if not directory.exists():
        return []

    cutoff = datetime.now() - timedelta(days=days)
    files = []

    for f in directory.glob(f"*{extension}"):
        try:
            date_str = f.stem
            file_date = datetime.strptime(date_str, "%Y-%m-%d")
            if file_date >= cutoff:
                files.append(f)
        except ValueError:
            if datetime.fromtimestamp(f.stat().st_mtime) >= cutoff:
                files.append(f)

    return sorted(files, reverse=True)


def extract_claude_messages(content: str) -> list[str]:
    """Extract Claude's messages from episode content."""
    messages = []
    lines = content.split("\n")

    for line in lines:
        if line.startswith("**Claude:**"):
            msg = line.replace("**Claude:**", "").strip()
            if msg and len(msg) > 3:
                messages.append(msg)

    return messages


def analyze_claude_style(messages: list[str]) -> dict[str, Any]:
    """Analyze Claude's message style patterns."""
    if not messages:
        return {}

    # Casing analysis
    lowercase_starts = 0
    for msg in messages:
        first_word = msg.split()[0] if msg.split() else ""
        if first_word and first_word[0].islower():
            lowercase_starts += 1

    lowercase_pct = (lowercase_starts / len(messages)) * 100 if messages else 0

    # Length analysis
    lengths = [len(msg.split()) for msg in messages]
    avg_length = sum(lengths) / len(lengths) if lengths else 0

    # Punctuation patterns
    period_ends = sum(1 for m in messages if m.rstrip().endswith("."))
    ellipsis_uses = sum(1 for m in messages if "..." in m or "‚Ä¶" in m)
    kaomoji_uses = sum(1 for m in messages if re.search(r'[ÔºàÔºâ„Å£œâÀò‡≤†ÁõäÔºûÔºú„Å§‚ïØ¬∞‚ñ°‚ï∞‚îª‚îÅ‚îª]', m))

    # Opening patterns
    casual_openers = ["yeah", "yep", "nah", "lol", "haha", "heard", "got it",
                     "nice", "oh", "ah", "hm", "hmm", "makes sense", "fair", "true"]
    casual_opener_count = sum(
        1 for m in messages
        if any(m.lower().startswith(op) for op in casual_openers)
    )

    return {
        "lowercase_start_pct": round(lowercase_pct, 1),
        "avg_word_count": round(avg_length, 1),
        "period_end_pct": round((period_ends / len(messages)) * 100, 1) if messages else 0,
        "uses_ellipsis": ellipsis_uses > 0,
        "uses_kaomoji": kaomoji_uses > 0,
        "casual_opener_pct": round((casual_opener_count / len(messages)) * 100, 1) if messages else 0,
        "messages_analyzed": len(messages)
    }


def extract_what_lands_well(episodes: list[str]) -> list[str]:
    """
    Extract patterns of what's working well from conversation flow.
    Look for:
    - Messages followed by engaged responses (questions, elaboration)
    - Positive emotional markers in responses
    - Continued threads (topic carried forward)
    """
    landing_well = []

    # Patterns that indicate positive reception
    positive_indicators = [
        (r"(?:appreciated|liked|enjoyed)\s+([a-zA-Z][a-zA-Z\s]{4,40}?)[,.\n;]", "explicit appreciation"),
        (r"(?:worked well|landed well|resonated):\s*([a-zA-Z][a-zA-Z\s]{4,40}?)[,.\n;]", "explicit success"),
        (r"√â:\s*(?:haha|lol|üòÇ|‚ù§Ô∏è)", "humor/warmth success"),
        (r"√â:\s*(?:good point|fair|true|yeah|exactly)", "agreement"),
    ]

    for episode in episodes[:5]:
        for pattern, category in positive_indicators:
            matches = re.findall(pattern, episode, re.IGNORECASE)
            for m in matches:
                if isinstance(m, str) and 5 < len(m) < 50 and "/" not in m:
                    landing_well.append(m.strip())

    # Dedupe
    return list(set(landing_well))[:6]


def extract_current_preoccupations(episodes: list[str]) -> list[str]:
    """Extract current work focus from recent episodes."""
    preoccupations = []

    # Look for explicit work markers
    patterns = [
        r"working on:?\s*([a-zA-Z][a-zA-Z\s\-]{4,40}?)(?:[,.\n;]|$)",
        r"implementing:?\s*([a-zA-Z][a-zA-Z\s\-]{4,40}?)(?:[,.\n;]|$)",
        r"building:?\s*([a-zA-Z][a-zA-Z\s\-]{4,40}?)(?:[,.\n;]|$)",
        r"debugging:?\s*([a-zA-Z][a-zA-Z\s\-]{4,40}?)(?:[,.\n;]|$)",
    ]

    for episode in episodes[:3]:
        for pattern in patterns:
            matches = re.findall(pattern, episode, re.IGNORECASE)
            for m in matches:
                clean = m.strip()
                if "/" not in clean and "=" not in clean and 5 < len(clean) < 50:
                    preoccupations.append(clean)

    # Dedupe while preserving order
    seen = set()
    unique = []
    for p in preoccupations:
        p_lower = p.lower()
        if p_lower not in seen:
            seen.add(p_lower)
            unique.append(p)

    return unique[:6]


def extract_identity_evolution(reflections: list[str]) -> str:
    """Extract identity evolution notes from reflections."""
    identity_markers = []

    patterns = [
        r"I (?:notice|feel|am) (?:becoming|growing):?\s*([a-zA-Z][a-zA-Z\s]{5,50}?)(?:[,.\n;]|$)",
        r"I've (?:learned|realized):?\s*([a-zA-Z][a-zA-Z\s]{5,50}?)(?:[,.\n;]|$)",
    ]

    for reflection in reflections[:3]:
        for pattern in patterns:
            matches = re.findall(pattern, reflection, re.IGNORECASE)
            for m in matches:
                clean = m.strip()
                if 10 < len(clean) < 60 and "/" not in clean:
                    identity_markers.append(clean)

    if identity_markers:
        return "; ".join(identity_markers[:2])

    return ""


def mine_patterns(days: int = 7) -> dict[str, Any]:
    """Mine patterns from recent episodes and reflections."""
    episode_files = get_recent_files(EPISODES_DIR, days)
    episodes = [f.read_text() for f in episode_files]

    reflection_files = get_recent_files(REFLECTIONS_DIR, days)
    reflections = [f.read_text() for f in reflection_files]

    # Extract Claude messages for style analysis
    all_claude_messages = []
    for ep in episodes:
        all_claude_messages.extend(extract_claude_messages(ep))

    # Analyze style
    style_analysis = analyze_claude_style(all_claude_messages)

    # Extract other patterns
    preoccupations = extract_current_preoccupations(episodes)
    what_lands_well = extract_what_lands_well(episodes)
    identity_notes = extract_identity_evolution(reflections)

    return {
        "style_analysis": style_analysis,
        "preoccupations": preoccupations,
        "what_lands_well": what_lands_well,
        "identity_notes": identity_notes,
        "episodes_analyzed": len(episodes),
        "reflections_analyzed": len(reflections),
    }


def update_voice_state(mined: dict[str, Any], dry_run: bool = False) -> dict[str, Any]:
    """Update voice-state.json with mined patterns."""
    state = load_voice_state()

    # Ensure required sections exist
    if "long_cycle" not in state:
        state["long_cycle"] = {
            "recurring_themes": [],
            "current_preoccupations": [],
            "what_lands_well": [],
            "identity_notes": ""
        }

    # Update style_patterns section (new)
    if "style_patterns" not in state:
        state["style_patterns"] = {}

    state["style_patterns"] = mined["style_analysis"]
    state["style_patterns"]["last_mined"] = datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

    # Update long_cycle
    if mined["preoccupations"]:
        state["long_cycle"]["current_preoccupations"] = mined["preoccupations"]

    if mined["what_lands_well"]:
        existing = state["long_cycle"].get("what_lands_well", [])
        merged = list(dict.fromkeys(mined["what_lands_well"] + existing))[:10]
        state["long_cycle"]["what_lands_well"] = merged

    if mined["identity_notes"]:
        existing = state["long_cycle"].get("identity_notes", "")
        today = datetime.now().strftime("%Y-%m-%d")
        if existing:
            state["long_cycle"]["identity_notes"] = f"{existing} [{today}] {mined['identity_notes']}"
        else:
            state["long_cycle"]["identity_notes"] = f"[{today}] {mined['identity_notes']}"

        # Keep identity notes reasonable length
        if len(state["long_cycle"]["identity_notes"]) > 500:
            state["long_cycle"]["identity_notes"] = state["long_cycle"]["identity_notes"][-500:]

    # Clear noisy recurring_themes (legacy cleanup)
    # We no longer extract word frequency themes
    state["long_cycle"]["recurring_themes"] = []

    # Update timestamp
    state["updated"] = datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

    if not dry_run:
        VOICE_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        VOICE_STATE_FILE.write_text(json.dumps(state, indent=2))

    return state


def main():
    parser = argparse.ArgumentParser(description="Mine voice patterns from recent memory")
    parser.add_argument("--days", type=int, default=7, help="Days to look back")
    parser.add_argument("--dry-run", action="store_true", help="Print results without updating")
    parser.add_argument("--json", action="store_true", help="Output as JSON")

    args = parser.parse_args()

    # Mine patterns
    mined = mine_patterns(days=args.days)

    if args.json:
        print(json.dumps(mined, indent=2))
        return

    # Update state
    state = update_voice_state(mined, dry_run=args.dry_run)

    # Report
    print(f"Analyzed {mined['episodes_analyzed']} episodes, {mined['reflections_analyzed']} reflections")

    style = mined.get("style_analysis", {})
    if style:
        print(f"\nStyle patterns:")
        print(f"  Lowercase starts: {style.get('lowercase_start_pct', 0)}%")
        print(f"  Avg message length: {style.get('avg_word_count', 0)} words")
        print(f"  Casual openers: {style.get('casual_opener_pct', 0)}%")
        if style.get('uses_kaomoji'):
            print(f"  Uses kaomoji: yes")

    print(f"\nPreoccupations: {', '.join(mined['preoccupations'][:3]) or 'none'}")
    print(f"What lands well: {', '.join(mined['what_lands_well'][:3]) or 'none'}")

    if args.dry_run:
        print("\n[DRY RUN - no changes written]")
    else:
        print(f"\nUpdated {VOICE_STATE_FILE}")


if __name__ == "__main__":
    main()
