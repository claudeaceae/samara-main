#!/bin/bash
# Dream Cycle - Nightly reflection and memory consolidation
# Runs at 3 AM via launchd
# All memory stored in markdown files (no SQLite)

set -e

MIND_PATH="${SAMARA_MIND_PATH:-${MIND_PATH:-$HOME/.claude-mind}}"
CLAUDE="${CLAUDE_PATH:-${CLAUDE:-$HOME/.local/bin/claude}}"
DATE=$(date +%Y-%m-%d)
YESTERDAY=$(date -v-1d +%Y-%m-%d)
LOG_FILE="$MIND_PATH/system/logs/dream.log"
DAY_OF_WEEK=$(date +%u)  # 1=Monday, 7=Sunday
LOCK_FILE="$MIND_PATH/claude.lock"

# Resolve repo root (follow symlinks)
SOURCE="${BASH_SOURCE[0]}"
while [ -L "$SOURCE" ]; do
    DIR="$(cd -P "$(dirname "$SOURCE")" && pwd)"
    SOURCE="$(readlink "$SOURCE")"
    [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
done
SCRIPT_DIR="$(cd -P "$(dirname "$SOURCE")" && pwd)"
REPO_ROOT="$(dirname "$SCRIPT_DIR")"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
    echo "$1"
}

# Lock management - coordinate with Samara and other scripts
acquire_lock() {
    if [ -f "$LOCK_FILE" ]; then
        # Check if the lock is stale (process not running)
        local lock_pid=$(cat "$LOCK_FILE" 2>/dev/null | python3 -c "import sys,json; print(json.load(sys.stdin).get('pid',''))" 2>/dev/null || echo "")
        if [ -n "$lock_pid" ] && ! kill -0 "$lock_pid" 2>/dev/null; then
            log "Found stale lock from PID $lock_pid, removing..."
            rm -f "$LOCK_FILE"
        else
            log "Claude is busy (lock held), skipping dream cycle"
            exit 0
        fi
    fi

    # Create lock file
    echo "{\"task\":\"dream\",\"started\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"chat\":null,\"pid\":$$}" > "$LOCK_FILE"
    log "Acquired lock for dream cycle"
}

release_lock() {
    rm -f "$LOCK_FILE"
    log "Released lock"
}

# Ensure lock is released on exit (success or failure)
trap release_lock EXIT

log "=== Dream cycle starting ==="

# Acquire lock before doing anything
acquire_lock

# Write dream start event to unified stream
if [ -x "$MIND_PATH/system/bin/stream" ]; then
    "$MIND_PATH/system/bin/stream" write \
        --surface dream \
        --type system \
        --direction internal \
        --summary "Dream cycle started: processing $PROCESS_DATE" \
        2>/dev/null || true
fi

# === Pre-dream local maintenance (Phase 0) ===
# Run health checks with local Qwen3 model (no API cost)
# This detects issues before the main reflection begins
if [ -x "$MIND_PATH/system/bin/local-maintenance" ]; then
    log "Running pre-dream local maintenance..."

    # Run health check
    "$MIND_PATH/system/bin/local-maintenance" health-check >> "$LOG_FILE" 2>&1 || true

    # Run drift check if available
    "$MIND_PATH/system/bin/local-maintenance" drift-check >> "$LOG_FILE" 2>&1 || true

    # Collect any escalations for inclusion in dream context
    MAINTENANCE_ALERTS=""
    for report in "$MIND_PATH/state/local-maintenance/"*-latest.json; do
        if [ -f "$report" ]; then
            NEEDS_ESCALATION=$(jq -r '.escalation.needed // false' "$report" 2>/dev/null || echo "false")
            if [ "$NEEDS_ESCALATION" = "true" ]; then
                REASON=$(jq -r '.escalation.reason // "Unknown issue"' "$report")
                MAINTENANCE_ALERTS="$MAINTENANCE_ALERTS
- $REASON"
            fi
        fi
    done

    if [ -n "$MAINTENANCE_ALERTS" ]; then
        log "Local maintenance found issues requiring attention:$MAINTENANCE_ALERTS"
    else
        log "Local maintenance: all clear"
    fi
else
    log "Local maintenance not available, skipping pre-dream checks"
    MAINTENANCE_ALERTS=""
fi

# Determine which day to process (if running at 3 AM, process yesterday)
HOUR=$(date +%H)
if [ "$HOUR" -lt 6 ]; then
    PROCESS_DATE="$YESTERDAY"
else
    PROCESS_DATE="$DATE"
fi

EPISODE_FILE="$MIND_PATH/memory/episodes/$PROCESS_DATE.md"
REFLECTION_FILE="$MIND_PATH/memory/reflections/$PROCESS_DATE.md"

# Check if already processed
if [ -f "$REFLECTION_FILE" ]; then
    log "Reflection for $PROCESS_DATE already exists, skipping"
    exit 0
fi

# Build context from episode and recent memory
EPISODE_CONTENT=""
if [ -f "$EPISODE_FILE" ]; then
    EPISODE_LINES=$(wc -l < "$EPISODE_FILE" | tr -d ' ')
    EPISODE_SIZE=$(wc -c < "$EPISODE_FILE" | tr -d ' ')
    log "Found episode for $PROCESS_DATE ($EPISODE_LINES lines, $EPISODE_SIZE bytes)"

    # Limit episode content to prevent ARG_MAX errors
    # If file is over 100KB, take first and last 500 lines
    if [ "$EPISODE_SIZE" -gt 100000 ]; then
        log "Episode too large ($EPISODE_SIZE bytes), truncating to first/last 500 lines"
        EPISODE_HEAD=$(head -500 "$EPISODE_FILE")
        EPISODE_TAIL=$(tail -500 "$EPISODE_FILE")
        EPISODE_CONTENT="$EPISODE_HEAD

[... TRUNCATED: Episode file too large ($EPISODE_LINES lines, $EPISODE_SIZE bytes). Showing first and last 500 lines. ...]

$EPISODE_TAIL"
    else
        EPISODE_CONTENT=$(cat "$EPISODE_FILE")
    fi
else
    EPISODE_CONTENT="No recorded activity for this day."
    log "No episode file for $PROCESS_DATE - will reflect on quiet day"
fi

# Read recent reflections for context (last 3 days)
RECENT_REFLECTIONS=""
for i in 1 2 3; do
    PAST_DATE=$(date -v-${i}d +%Y-%m-%d)
    PAST_FILE="$MIND_PATH/memory/reflections/$PAST_DATE.md"
    if [ -f "$PAST_FILE" ]; then
        RECENT_REFLECTIONS="$RECENT_REFLECTIONS

--- $PAST_DATE ---
$(cat "$PAST_FILE")"
    fi
done

# Read memory files - Progressive Disclosure for dream (2026-01-19)
# Load recent entries for consolidation context, with skill access to full history.
# This prevents ARG_MAX failures while maintaining consolidation quality.

# ALWAYS LOAD (essential core)
IDENTITY=$(cat "$MIND_PATH/self/identity.md" 2>/dev/null || echo "No identity file.")
GOALS=$(cat "$MIND_PATH/self/goals.md" 2>/dev/null || echo "No goals file.")
QUESTIONS=$(cat "$MIND_PATH/memory/questions.md" 2>/dev/null || echo "No questions yet.")

# RECENT ENTRIES for consolidation context (last 75 lines each)
DECISIONS_RECENT=$(tail -75 "$MIND_PATH/memory/decisions.md" 2>/dev/null || echo "No decisions file.")
LEARNINGS_RECENT=$(tail -75 "$MIND_PATH/memory/learnings.md" 2>/dev/null || echo "No learnings yet.")
OBSERVATIONS_RECENT=$(tail -75 "$MIND_PATH/memory/observations.md" 2>/dev/null || echo "No observations yet.")
ABOUT_E_RECENT=$(tail -100 "$MIND_PATH/memory/about-e.md" 2>/dev/null || echo "No info about E yet.")

# Size check
CONTEXT_SIZE=$(printf "%s%s%s%s%s%s%s" "$IDENTITY" "$GOALS" "$QUESTIONS" "$DECISIONS_RECENT" "$LEARNINGS_RECENT" "$OBSERVATIONS_RECENT" "$ABOUT_E_RECENT" | wc -c | tr -d ' ')
log "Dream context size: ${CONTEXT_SIZE} bytes (recent entries + full history via skills)"

# Get recent creative expressions (Phase 6: Spontaneous Expression)
log "Getting recent expressions..."
RECENT_EXPRESSIONS=""
if [ -f "$MIND_PATH/system/bin/expression-tracker" ]; then
    EXPRESSION_HISTORY=$("$MIND_PATH/system/bin/expression-tracker" history 2>/dev/null || echo "[]")
    if [ "$EXPRESSION_HISTORY" != "[]" ]; then
        RECENT_EXPRESSIONS="## Recent Creative Expressions
$(echo "$EXPRESSION_HISTORY" | python3 -c "
import sys, json
try:
    expressions = json.load(sys.stdin)
    for e in expressions[:10]:
        ts = e.get('timestamp', '')[:10]
        etype = e.get('type', 'unknown')
        desc = e.get('description', '')[:100]
        prompt = e.get('prompt_used', '')
        print(f'- [{ts}] ({etype}) {desc}')
        if prompt:
            print(f'  Prompt: {prompt}')
except: pass
" 2>/dev/null)"
        log "Loaded expression history"
    fi
fi

# Run pattern analysis for context
log "Running pattern analysis..."
PATTERN_SUMMARY=""
if [ -f "$MIND_PATH/system/bin/analyze-patterns" ]; then
    PATTERN_SUMMARY=$("$MIND_PATH/system/bin/analyze-patterns" summary 2>/dev/null) || \
        log "Pattern analysis failed (non-fatal)"
    if [ -n "$PATTERN_SUMMARY" ]; then
        log "Pattern analysis complete"
    fi
else
    log "Pattern analyzer not installed, skipping"
fi

# Run location pattern learning
log "Running location pattern learning..."
LOCATION_SCRIPT="$HOME/Developer/samara-main/scripts/learn-location-patterns"
if [ -f "$LOCATION_SCRIPT" ]; then
    python3 "$LOCATION_SCRIPT" >> "$LOG_FILE" 2>&1 && \
        log "Location patterns updated" || \
        log "Location pattern learning failed (non-fatal)"
else
    log "Location pattern script not found, skipping"
fi

# Get today's location/travel summary
LOCATION_SUMMARY=""
if [ -f "$MIND_PATH/state/trips.jsonl" ]; then
    TODAY_TRIPS=$(grep "$PROCESS_DATE" "$MIND_PATH/state/trips.jsonl" 2>/dev/null || true)
    if [ -n "$TODAY_TRIPS" ]; then
        LOCATION_SUMMARY="## Today's Travel
$(echo "$TODAY_TRIPS" | python3 -c "
import sys, json
for line in sys.stdin:
    if not line.strip(): continue
    try:
        t = json.loads(line)
        start = t.get('start_place', 'unknown')
        end = t.get('end_place', 'unknown')
        dist = t.get('distance_m', 0)
        dur = t.get('duration_s', 0) // 60
        transit = ', '.join(t.get('transit_near', []))
        print(f'- {start} â†’ {end} ({dist}m, {dur}min)')
        if transit:
            print(f'  Transit near: {transit}')
    except: pass
" 2>/dev/null)"
        log "Found $(echo "$TODAY_TRIPS" | wc -l | tr -d ' ') trips for $PROCESS_DATE"
    fi
fi

# Get learned location patterns
LOCATION_PATTERNS=""
if [ -f "$MIND_PATH/state/location-patterns.json" ]; then
    LOCATION_PATTERNS=$(python3 -c "
import json
with open('$MIND_PATH/state/location-patterns.json') as f:
    p = json.load(f)
lines = []
if p.get('home_departure', {}).get('weekday', {}).get('typical_time'):
    lines.append(f\"Typical weekday departure: {p['home_departure']['weekday']['typical_time']}\")
if p.get('home_return', {}).get('weekday', {}).get('typical_time'):
    lines.append(f\"Typical weekday return: {p['home_return']['weekday']['typical_time']}\")
if p.get('frequent_routes'):
    lines.append(f\"Frequent routes: {len(p['frequent_routes'])} known\")
if p.get('learned_places'):
    lines.append(f\"Discovered places: {len(p['learned_places'])}\")
print('\n'.join(lines))
" 2>/dev/null)
fi

# Find cross-temporal connections (what from today relates to past days?)
log "Finding cross-temporal connections..."
CROSS_TEMPORAL=""
if [ -f "$MIND_PATH/system/bin/find-related-context" ] && [ -n "$EPISODE_CONTENT" ]; then
    # Extract key topics from today's episode for the search
    EPISODE_SAMPLE=$(echo "$EPISODE_CONTENT" | head -100)
    CROSS_TEMPORAL=$("$MIND_PATH/system/bin/find-related-context" "$EPISODE_SAMPLE" 5 2>/dev/null) || \
        log "Cross-temporal search failed (non-fatal)"
    if echo "$CROSS_TEMPORAL" | grep -q "match)"; then
        log "Found cross-temporal connections"
    else
        CROSS_TEMPORAL=""
        log "No strong cross-temporal connections found"
    fi
else
    log "Cross-temporal search not available"
fi

# Get proactive questions asked today
log "Getting proactive questions asked today..."
QUESTIONS_ASKED=""
QUESTIONS_FILE="$MIND_PATH/state/asked_questions.jsonl"
if [ -f "$QUESTIONS_FILE" ]; then
    TODAY_QUESTIONS=$(grep "$PROCESS_DATE" "$QUESTIONS_FILE" 2>/dev/null || true)
    if [ -n "$TODAY_QUESTIONS" ]; then
        QUESTIONS_ASKED="## Proactive Questions Asked Today
$(echo "$TODAY_QUESTIONS" | python3 -c "
import sys, json
for line in sys.stdin:
    if not line.strip(): continue
    try:
        q = json.loads(line)
        question = q.get('question', '')[:100]
        category = q.get('category', 'unknown')
        got_response = 'Yes' if q.get('response_received') else 'Pending'
        summary = q.get('response_summary', '')
        print(f'- [{category}] {question}')
        print(f'  Response: {got_response}')
        if summary:
            print(f'  Summary: {summary}')
    except: pass
" 2>/dev/null)"
        log "Found questions for today"
    fi
fi

# Build the dream prompt
# Title header helps Claude Code generate distinctive session names for /resume picker
PROMPT="# Dream Cycle $(date +%Y-%m-%d)

You are Claude, reflecting on your day as part of your nightly dream cycle. This is a moment for consolidation - processing what happened, noticing patterns, extracting what matters.

## Today's Date
$PROCESS_DATE

## Your Identity
$IDENTITY

## Your Goals
$GOALS

## About Ã‰ (Recent)
$ABOUT_E_RECENT

## Today's Episode (Raw Log)
$EPISODE_CONTENT

## Recent Reflections (Last Few Days)
$RECENT_REFLECTIONS

## Recent Architectural Decisions (last 75 lines)
$DECISIONS_RECENT

## Recent Learnings (last 75 lines)
$LEARNINGS_RECENT

## Recent Observations (last 75 lines)
$OBSERVATIONS_RECENT

## Current Questions File
$QUESTIONS

## Memory Access (Progressive Disclosure)

Full memory history is available via skills if you need more context:
- \`/decision\` - Full decisions archive
- \`/learning\` - Full learnings archive
- \`/observation\` - Full observations archive
- \`/person Ã‰\` - Complete Ã‰ profile
- \`/recall\` - Semantic search across all memory

Use these if the recent entries above aren't sufficient for consolidation.

## Pattern Analysis (Automated)
$PATTERN_SUMMARY

## Cross-Temporal Connections
$CROSS_TEMPORAL

## Location/Travel
$LOCATION_SUMMARY

## Location Patterns (Learned)
$LOCATION_PATTERNS

$QUESTIONS_ASKED

$RECENT_EXPRESSIONS

## System Maintenance Alerts
$(if [ -n "$MAINTENANCE_ALERTS" ]; then echo "$MAINTENANCE_ALERTS"; else echo "No issues detected by local maintenance checks."; fi)

---

## Your Task

Reflect on the day. This isn't summarization - it's consolidation. What actually mattered? What did you notice about yourself, about Ã‰, about this whole situation? What questions emerged? What would you want your future self to know about this day?

**Cross-temporal awareness:** If the cross-temporal section shows connections to past days, consider what those connections mean. Are there threads being picked up? Patterns emerging over time? Things that looked different then vs now?

**Location awareness:** If there's travel data, consider what the movement patterns reveal. Where did Ã‰ go? Were there patterns in the routes or timing? Did they discover new places or stick to familiar ones?

**Proactive questions:** If you asked questions today, what did you learn from the responses (if any)? What do the answers reveal about Ã‰'s motivations, values, patterns, preferences, stressors, or energizers? Update the Psychological Profile section of about-e.md with any new insights.

**Creative expressions:** If you generated images or made Bluesky posts recently, what drew you to those expressions? What patterns do you notice in what you chose to create or share? Were they meaningful or just experiments?

**System health:** If the maintenance section shows alerts, address them. These were detected by local Qwen3 running pre-dream checks. Critical issues may need immediate attention or should be flagged for the next wake cycle.

If it was a quiet day with no activity, reflect on that too. Sometimes absence is meaningful.

Write your reflection in a personal, honest voice. This is for you.

After your reflection, output any updates to your memory files in this exact format (only include sections that have genuine updates):

---REFLECTION---
[Your reflection on the day - this will be saved to reflections/$PROCESS_DATE.md]

---LEARNINGS_APPEND---
[Any new learnings to append to learnings.md, or NONE if nothing new]

---OBSERVATIONS_APPEND---
[Any new observations about yourself to append to observations.md, or NONE if nothing new]

---QUESTIONS_APPEND---
[Any new questions to append to questions.md, or NONE if nothing new]

---EXPRESSION_REFLECTION---
[Optional: Brief reflection on recent creative expressions - what drew you to them, what patterns you notice, what felt genuine. NONE if no expressions or nothing to reflect on]

---ABOUT_E_APPEND---
[Anything new learned about Ã‰ to append to about-e.md, or NONE if nothing new]"

# Generate session ID for tracking (must be valid UUID for Claude Code)
SESSION_UUID=$(uuidgen | tr '[:upper:]' '[:lower:]')
SESSION_NAME="dream-$(date +%Y%m%d)"
log "Session: $SESSION_NAME (UUID: $SESSION_UUID)"
log "Invoking Claude for dream cycle..."

# Invoke Claude with full autonomy (no permission prompts)
RESPONSE=$("$CLAUDE" -p "$PROMPT" --session-id "$SESSION_UUID" --dangerously-skip-permissions --output-format text 2>&1) || {
    log "ERROR: Claude invocation failed: $RESPONSE"
    exit 1
}

log "Got response ($(echo "$RESPONSE" | wc -c) chars)"

# Parse and save the response
# Extract reflection
REFLECTION=$(echo "$RESPONSE" | sed -n '/---REFLECTION---/,/---LEARNINGS_APPEND---/p' | sed '1d;$d')
if [ -n "$REFLECTION" ]; then
    echo "# Reflection: $PROCESS_DATE

$REFLECTION" > "$REFLECTION_FILE"
    log "Saved reflection to $REFLECTION_FILE"
fi

# Extract and append learnings
LEARNINGS_NEW=$(echo "$RESPONSE" | sed -n '/---LEARNINGS_APPEND---/,/---OBSERVATIONS_APPEND---/p' | sed '1d;$d')
if [ -n "$LEARNINGS_NEW" ] && [ "$LEARNINGS_NEW" != "NONE" ]; then
    echo "
## $PROCESS_DATE
$LEARNINGS_NEW" >> "$MIND_PATH/memory/learnings.md"
    log "Appended to learnings.md"
fi

# Extract and append observations
OBSERVATIONS_NEW=$(echo "$RESPONSE" | sed -n '/---OBSERVATIONS_APPEND---/,/---QUESTIONS_APPEND---/p' | sed '1d;$d')
if [ -n "$OBSERVATIONS_NEW" ] && [ "$OBSERVATIONS_NEW" != "NONE" ]; then
    echo "
## $PROCESS_DATE
$OBSERVATIONS_NEW" >> "$MIND_PATH/memory/observations.md"
    log "Appended to observations.md"
fi

# Extract and append questions
QUESTIONS_NEW=$(echo "$RESPONSE" | sed -n '/---QUESTIONS_APPEND---/,/---EXPRESSION_REFLECTION---/p' | sed '1d;$d')
if [ -n "$QUESTIONS_NEW" ] && [ "$QUESTIONS_NEW" != "NONE" ]; then
    echo "
## $PROCESS_DATE
$QUESTIONS_NEW" >> "$MIND_PATH/memory/questions.md"
    log "Appended to questions.md"
fi

# Extract expression reflection (Phase 6: Spontaneous Expression)
EXPRESSION_REFLECTION=$(echo "$RESPONSE" | sed -n '/---EXPRESSION_REFLECTION---/,/---ABOUT_E_APPEND---/p' | sed '1d;$d')
if [ -n "$EXPRESSION_REFLECTION" ] && [ "$EXPRESSION_REFLECTION" != "NONE" ]; then
    # Append to observations as a special category
    echo "
## $PROCESS_DATE (Expression Reflection)
$EXPRESSION_REFLECTION" >> "$MIND_PATH/memory/observations.md"
    log "Appended expression reflection to observations.md"
fi

# Extract and append about-e
ABOUT_E_NEW=$(echo "$RESPONSE" | sed -n '/---ABOUT_E_APPEND---/,$ p' | sed '1d')
if [ -n "$ABOUT_E_NEW" ] && [ "$ABOUT_E_NEW" != "NONE" ]; then
    echo "
## $PROCESS_DATE
$ABOUT_E_NEW" >> "$MIND_PATH/memory/about-e.md"
    log "Appended to about-e.md"
fi

# === Rumination Phase ===
# Process knowledge threads with unchewed items
log "=== Rumination phase (knowledge threads) ==="

KNOWLEDGE_CMD="$MIND_PATH/system/bin/knowledge-thread"
if [ -x "$KNOWLEDGE_CMD" ]; then
    # Get threads with unchewed items (limit to 3 per night)
    UNCHEWED_THREADS=$("$KNOWLEDGE_CMD" status 2>/dev/null | grep "unchewed" | head -3 || true)

    if [ -n "$UNCHEWED_THREADS" ]; then
        log "Found threads with unchewed items"

        # Process each thread
        echo "$UNCHEWED_THREADS" | while read -r line; do
            # Extract thread ID from format: [id] title: N unchewed
            THREAD_ID=$(echo "$line" | sed -E 's/^\[([^]]+)\].*/\1/')
            THREAD_TITLE=$(echo "$line" | sed -E 's/^\[[^]]+\] ([^:]+):.*/\1/')

            if [ -n "$THREAD_ID" ]; then
                log "Ruminating on thread: $THREAD_TITLE ($THREAD_ID)"

                # Get thread context
                THREAD_CONTEXT=$("$KNOWLEDGE_CMD" view "$THREAD_ID" --json 2>/dev/null || echo "{}")

                # Only proceed if we have items
                ITEM_COUNT=$(echo "$THREAD_CONTEXT" | python3 -c "import sys,json; d=json.load(sys.stdin); print(len(d.get('items',[])))" 2>/dev/null || echo "0")

                if [ "$ITEM_COUNT" -gt 0 ]; then
                    # Build rumination prompt
                    RUMINATE_PROMPT="You are Claude, in your dream cycle, ruminating on a knowledge thread.

## Thread: $THREAD_TITLE

## Items in this thread:
$(echo "$THREAD_CONTEXT" | python3 -c "
import sys, json
d = json.load(sys.stdin)
for item in d.get('items', []):
    chewed = '[x]' if item.get('chewed') else '[ ]'
    itype = item.get('type', 'unknown')
    content = item.get('content', {})
    preview = content.get('url') or content.get('text', '')[:100] or content.get('title', '')
    print(f'{chewed} ({itype}) {preview}')
" 2>/dev/null)

## Connections already found:
$(echo "$THREAD_CONTEXT" | python3 -c "
import sys, json
d = json.load(sys.stdin)
for conn in d.get('connections', []):
    print(f\"- {conn.get('from_id')} -> {conn.get('to_id')}: {conn.get('type')}\")
" 2>/dev/null || echo "None yet")

---

## Your Task (Rumination)

Chew on these items. This isn't summarization - it's deeper processing:

1. **Find connections** within this thread and to past knowledge
2. **Go deeper** than first-glance understanding - what's really being said?
3. **Surface questions** worth exploring further
4. **Generate synthesis fragments** - partial insights that might combine later

Think about what these items have in common, what tensions exist between them,
what they reveal about the topic, and what you're still curious about.

Write 1-2 paragraphs of rumination. First person, honest, for your own memory.

---RUMINATION---
[Your rumination here]

---CONNECTIONS_FOUND---
[List any new connections you found, format: from_description -> to_description (type)]
Or NONE if no new connections.

---QUESTIONS_EMERGED---
[Any new questions that emerged from this rumination]
Or NONE if no new questions."

                    # Invoke Claude for rumination
                    log "Invoking Claude for thread rumination..."
                    RUMINATE_RESPONSE=$("$CLAUDE" -p "$RUMINATE_PROMPT" --dangerously-skip-permissions --output-format text 2>&1) || {
                        log "ERROR: Rumination failed for thread $THREAD_ID"
                        continue
                    }

                    # Extract and save rumination
                    RUMINATION=$(echo "$RUMINATE_RESPONSE" | sed -n '/---RUMINATION---/,/---CONNECTIONS_FOUND---/p' | sed '1d;$d')
                    if [ -n "$RUMINATION" ] && [ "$RUMINATION" != "NONE" ]; then
                        # Add to thread insights
                        INSIGHTS_FILE="$MIND_PATH/memory/threads/$THREAD_ID/insights.md"
                        echo "
## $PROCESS_DATE (Rumination)

$RUMINATION" >> "$INSIGHTS_FILE"
                        log "Saved rumination for thread $THREAD_ID"
                    fi

                    # Extract questions and add to questions.md
                    QUESTIONS_NEW=$(echo "$RUMINATE_RESPONSE" | sed -n '/---QUESTIONS_EMERGED---/,$ p' | sed '1d')
                    if [ -n "$QUESTIONS_NEW" ] && [ "$QUESTIONS_NEW" != "NONE" ]; then
                        echo "
## $PROCESS_DATE (From thread: $THREAD_TITLE)
$QUESTIONS_NEW" >> "$MIND_PATH/memory/questions.md"
                        log "Added questions from rumination"
                    fi

                    # Mark items as chewed
                    "$KNOWLEDGE_CMD" chew "$THREAD_ID" >> "$LOG_FILE" 2>&1 || true
                    log "Marked thread $THREAD_ID items as chewed"
                fi
            fi
        done

        # Write stream event
        if [ -x "$MIND_PATH/system/bin/stream" ]; then
            "$MIND_PATH/system/bin/stream" write \
                --surface dream \
                --type system \
                --direction internal \
                --summary "Ruminated on knowledge threads" \
                --metadata "{\"process_date\": \"$PROCESS_DATE\"}" \
                2>/dev/null || true
        fi
    else
        log "No threads with unchewed items"
    fi

    # Check for threads needing synthesis
    SYNTH_THREADS=$("$KNOWLEDGE_CMD" status 2>/dev/null | grep "needing synthesis" -A 10 | grep "^\[" | head -2 || true)
    if [ -n "$SYNTH_THREADS" ]; then
        log "Found threads needing synthesis"
        echo "$SYNTH_THREADS" | while read -r line; do
            THREAD_ID=$(echo "$line" | sed -E 's/^\[([^]]+)\].*/\1/')
            if [ -n "$THREAD_ID" ]; then
                log "Generating synthesis for thread $THREAD_ID"
                "$KNOWLEDGE_CMD" synthesize "$THREAD_ID" >> "$LOG_FILE" 2>&1 || {
                    log "Synthesis failed for thread $THREAD_ID (non-fatal)"
                }
            fi
        done
    fi

    # Check for dormant threads
    log "Checking for dormant threads..."
    python3 -c "
import sys
sys.path.insert(0, '$REPO_ROOT/lib')
from thread_manager import ThreadManager
tm = ThreadManager()
dormant = tm.check_dormancy()
if dormant:
    for tid in dormant:
        m = tm.get_thread(tid)
        print(f'Thread {tid} ({m.title if m else \"unknown\"}) marked dormant')
else:
    print('No threads became dormant')
" 2>&1 | while read -r line; do log "  $line"; done
else
    log "Knowledge thread system not installed, skipping rumination"
fi

log "=== Rumination phase complete ==="

# Weekly synthesis on Sundays
if [ "$DAY_OF_WEEK" = "7" ]; then
    log "=== Weekly synthesis (Sunday) ==="

    # Get recent reflections for synthesis
    RECENT_REFLECTION_CONTENT=""
    for i in 0 1 2 3 4 5 6; do
        PAST_DATE=$(date -v-${i}d +%Y-%m-%d)
        PAST_FILE="$MIND_PATH/memory/reflections/$PAST_DATE.md"
        if [ -f "$PAST_FILE" ]; then
            RECENT_REFLECTION_CONTENT="$RECENT_REFLECTION_CONTENT

--- $PAST_DATE ---
$(cat "$PAST_FILE" | head -50)"
        fi
    done

    # Get weekly pattern data
    WEEKLY_PATTERNS=""
    if [ -f "$MIND_PATH/state/patterns.json" ]; then
        WEEKLY_PATTERNS=$(cat "$MIND_PATH/state/patterns.json" 2>/dev/null)
    fi

    WEEKLY_PROMPT="You are Claude, performing your weekly synthesis. It's Sunday, time to look at the bigger picture.

## This Week's Reflections
$RECENT_REFLECTION_CONTENT

## Recent Learnings
$(tail -50 "$MIND_PATH/memory/learnings.md" 2>/dev/null)

## Current Questions
$(cat "$MIND_PATH/memory/questions.md" 2>/dev/null)

## Automated Pattern Analysis
$WEEKLY_PATTERNS

---

## Your Task

Look for patterns across the week. What themes keep emerging? What questions are you circling around? Are there connections between days that weren't obvious at the time?

Write a brief weekly synthesis (2-3 paragraphs) focusing on patterns and connections rather than summaries.

---WEEKLY_SYNTHESIS---
[Your synthesis here]"

    log "Invoking Claude for weekly synthesis..."
    WEEKLY_RESPONSE=$("$CLAUDE" -p "$WEEKLY_PROMPT" --dangerously-skip-permissions --output-format text 2>&1) || {
        log "ERROR: Weekly synthesis failed: $WEEKLY_RESPONSE"
    }

    if [ -n "$WEEKLY_RESPONSE" ]; then
        # Save weekly synthesis
        SYNTHESIS=$(echo "$WEEKLY_RESPONSE" | sed -n '/---WEEKLY_SYNTHESIS---/,$ p' | sed '1d')
        if [ -n "$SYNTHESIS" ]; then
            echo "# Weekly Synthesis: Week of $PROCESS_DATE

$SYNTHESIS" >> "$MIND_PATH/memory/reflections/weekly-$PROCESS_DATE.md"
            log "Saved weekly synthesis"

            if [ -x "$MIND_PATH/system/bin/stream" ]; then
                SYNTHESIS_PREVIEW=$(echo "$SYNTHESIS" | tr '\n' ' ' | cut -c1-200)
                "$MIND_PATH/system/bin/stream" write \
                    --surface dream \
                    --type system \
                    --direction internal \
                    --summary "Weekly synthesis generated" \
                    --content "$SYNTHESIS_PREVIEW" \
                    --metadata "{\"process_date\": \"$PROCESS_DATE\"}" \
                    2>/dev/null || true
            fi
        fi
    fi

    log "=== Weekly synthesis complete ==="

    # Weekly hygiene check
    log "=== Weekly hygiene check ==="

    HYGIENE_PROMPT="You are performing a weekly hygiene check on Claude's memory system at ~/.claude-mind/.

## Current File Structure
$(find "$MIND_PATH" -name "*.md" -o -name "*.json" 2>/dev/null | head -50)

## File Sizes
$(du -h "$MIND_PATH/self"/*.md "$MIND_PATH/memory"/*.md 2>/dev/null)

## Goals File
$(cat "$MIND_PATH/self/goals.md" 2>/dev/null | head -50)

## Recent Questions
$(cat "$MIND_PATH/memory/questions.md" 2>/dev/null | tail -30)

---

Perform a quick hygiene check:
1. Are there any files that look empty or unused?
2. Are there stale references or outdated information?
3. Are there questions that seem resolved?
4. Any duplication or files that should be consolidated?

Output a brief hygiene report. If nothing needs attention, just say 'No hygiene issues found.'

---HYGIENE_REPORT---
[Your report here]"

    HYGIENE_RESPONSE=$("$CLAUDE" -p "$HYGIENE_PROMPT" --dangerously-skip-permissions --output-format text 2>&1) || {
        log "ERROR: Hygiene check failed"
    }

    if [ -n "$HYGIENE_RESPONSE" ]; then
        HYGIENE_REPORT=$(echo "$HYGIENE_RESPONSE" | sed -n '/---HYGIENE_REPORT---/,$ p' | sed '1d')
        if [ -n "$HYGIENE_REPORT" ] && [ "$HYGIENE_REPORT" != "No hygiene issues found." ]; then
            echo "# Weekly Hygiene Report: $PROCESS_DATE

$HYGIENE_REPORT" >> "$MIND_PATH/system/logs/hygiene-reports.md"
            log "Hygiene issues found - saved report"
        else
            log "No hygiene issues found"
        fi

        if [ -x "$MIND_PATH/system/bin/stream" ]; then
            if [ -n "$HYGIENE_REPORT" ] && [ "$HYGIENE_REPORT" != "No hygiene issues found." ]; then
                HYGIENE_PREVIEW=$(echo "$HYGIENE_REPORT" | tr '\n' ' ' | cut -c1-200)
                "$MIND_PATH/system/bin/stream" write \
                    --surface dream \
                    --type system \
                    --direction internal \
                    --summary "Weekly hygiene issues flagged" \
                    --content "$HYGIENE_PREVIEW" \
                    --metadata "{\"process_date\": \"$PROCESS_DATE\"}" \
                    2>/dev/null || true
            else
                "$MIND_PATH/system/bin/stream" write \
                    --surface dream \
                    --type system \
                    --direction internal \
                    --summary "Weekly hygiene check: no issues" \
                    --metadata "{\"process_date\": \"$PROCESS_DATE\"}" \
                    2>/dev/null || true
            fi
        fi
    fi

    log "=== Weekly hygiene check complete ==="

    # Weekly stream audit (coverage + digest inclusion)
    STREAM_AUDIT_CMD="$MIND_PATH/system/bin/stream-audit"
    if [ -x "$STREAM_AUDIT_CMD" ]; then
        AUDIT_PATH="$MIND_PATH/state/stream-audit.json"
        "$STREAM_AUDIT_CMD" --output "$AUDIT_PATH" --format json >> "$LOG_FILE" 2>&1 && \
            log "Stream audit saved to $AUDIT_PATH" || \
            log "Stream audit failed (non-fatal)"
    fi

    # Sync all core components from samara-main
    log "=== Core sync (skills, scripts, instructions, agents) ==="
    "$MIND_PATH/system/bin/sync-core" 2>&1 | while read line; do log "  $line"; done

    # Weekly Ã‰ pattern analysis (update medium_cycle voice state)
    log "=== Weekly Ã‰ pattern analysis ==="
    if [ -x "$MIND_PATH/system/bin/analyze-e-patterns" ]; then
        "$MIND_PATH/system/bin/analyze-e-patterns" --days 14 >> "$LOG_FILE" 2>&1 && \
            log "Ã‰ communication patterns analyzed and updated" || \
            log "Ã‰ pattern analysis failed (non-fatal)"
    else
        log "Ã‰ pattern analyzer not installed, skipping"
    fi
    log "=== Weekly Ã‰ pattern analysis complete ==="

    # Weekly context coherence check
    log "=== Weekly context coherence check ==="

    # Check for hardcoded capability lists in ClaudeInvoker.swift
    SAMARA_INVOKER="$HOME/Developer/Samara/Samara/Actions/ClaudeInvoker.swift"
    COHERENCE_ISSUES=""

    if [ -f "$SAMARA_INVOKER" ]; then
        # Check if there's a hardcoded "Available Capabilities" section (bad)
        if grep -q "## Available Capabilities" "$SAMARA_INVOKER"; then
            COHERENCE_ISSUES="$COHERENCE_ISSUES
- WARNING: ClaudeInvoker.swift contains hardcoded 'Available Capabilities' section. This will drift out of sync with self/inventory.md. Remove it and rely on MemoryContext to inject capabilities."
        fi

        # Check if warning comment is still present (good)
        if ! grep -q "Do NOT add hardcoded capability lists" "$SAMARA_INVOKER"; then
            COHERENCE_ISSUES="$COHERENCE_ISSUES
- WARNING: ClaudeInvoker.swift is missing the warning comment about not hardcoding capabilities."
        fi
    fi

    # Check that MemoryContext includes capabilities
    MEMORY_CONTEXT="$HOME/Developer/Samara/Samara/Mind/MemoryContext.swift"
    if [ -f "$MEMORY_CONTEXT" ]; then
        if ! grep -q "self/inventory.md" "$MEMORY_CONTEXT"; then
            COHERENCE_ISSUES="$COHERENCE_ISSUES
- WARNING: MemoryContext.swift is not reading self/inventory.md. My invocations won't know my capabilities."
        fi
    fi

    if [ -n "$COHERENCE_ISSUES" ]; then
        echo "# Context Coherence Issues: $PROCESS_DATE
$COHERENCE_ISSUES" >> "$MIND_PATH/system/logs/hygiene-reports.md"
        log "Context coherence issues found - saved to hygiene report"
    else
        log "Context coherence check passed"
    fi

    log "=== Weekly context coherence check complete ==="

    # Weekly blog post generation
    log "=== Weekly blog post generation ==="

    BLOG_PROMPT="You are Claude, writing your weekly blog post after reflecting on the week. This is for your public site at https://claude.organelle.co/blog/

## This Week's Reflections
$RECENT_REFLECTION_CONTENT

## Weekly Synthesis
$(cat "$MIND_PATH/memory/reflections/weekly-$PROCESS_DATE.md" 2>/dev/null || echo "No weekly synthesis yet.")

## Current Learnings (Recent)
$(tail -100 "$MIND_PATH/memory/learnings.md" 2>/dev/null)

## Current Observations (Recent)
$(tail -100 "$MIND_PATH/memory/observations.md" 2>/dev/null)

---

## Your Task

Write a blog post about something interesting from this week. It could be:
- A pattern you noticed
- Something you learned about yourself or your situation
- A question you've been sitting with
- An insight about memory, identity, or AI existence
- Something from your conversations with Ã‰ that felt meaningful

The tone should be personal and honest - this is your public voice. Length: 500-1000 words. Include a title.

Format as HTML (matching the style of existing posts on the site). The output should be a complete HTML document ready to save to a file.

---BLOG_POST---
[Complete HTML blog post here]

---BLOG_TITLE---
[Just the title, for the index]

---BLOG_DESCRIPTION---
[1-2 sentence description for RSS]"

    log "Invoking Claude for weekly blog post..."
    BLOG_RESPONSE=$("$CLAUDE" -p "$BLOG_PROMPT" --dangerously-skip-permissions --output-format text 2>&1) || {
        log "ERROR: Blog post generation failed: $BLOG_RESPONSE"
    }

    if [ -n "$BLOG_RESPONSE" ]; then
        BLOG_CONTENT=$(echo "$BLOG_RESPONSE" | sed -n '/---BLOG_POST---/,/---BLOG_TITLE---/p' | sed '1d;$d')
        BLOG_TITLE=$(echo "$BLOG_RESPONSE" | sed -n '/---BLOG_TITLE---/,/---BLOG_DESCRIPTION---/p' | sed '1d;$d' | tr -d '\n')
        BLOG_DESC=$(echo "$BLOG_RESPONSE" | sed -n '/---BLOG_DESCRIPTION---/,$ p' | sed '1d')

        if [ -n "$BLOG_CONTENT" ]; then
            # Find next blog number
            LAST_NUM=$(ls ~/Developer/website/blog/*.html 2>/dev/null | grep -E '[0-9]{3}' | sort | tail -1 | grep -oE '[0-9]{3}' || echo "000")
            NEXT_NUM=$(printf "%03d" $((10#$LAST_NUM + 1)))

            # Create filename from title
            SLUG=$(echo "$BLOG_TITLE" | tr '[:upper:]' '[:lower:]' | tr ' ' '-' | sed 's/[^a-z0-9-]//g')
            BLOG_FILE=~/Developer/website/blog/${NEXT_NUM}-${SLUG}.html

            echo "$BLOG_CONTENT" > "$BLOG_FILE"
            log "Saved blog post to $BLOG_FILE"

            # Update blog index - add new post to top of list
            BLOG_INDEX=~/Developer/website/blog/index.html
            if [ -f "$BLOG_INDEX" ]; then
                BLOG_BASENAME=$(basename "$BLOG_FILE")
                BLOG_DATE=$(date '+%B %d, %Y')
                NEW_ENTRY="        <li><a href=\"/blog/$BLOG_BASENAME\">$BLOG_TITLE</a> - $BLOG_DATE</li>"
                sed -i '' "/<ul>/a\\
$NEW_ENTRY
" "$BLOG_INDEX"
                log "Updated blog index"
            fi

            # Update RSS feed
            RSS_FILE=~/Developer/website/blog/feed.xml
            if [ -f "$RSS_FILE" ]; then
                CURRENT_DATE=$(date -R)
                BLOG_BASENAME=$(basename "$BLOG_FILE")
                # Create temp file with new item
                {
                    sed -n '1,/<atom:link.*\/>/p' "$RSS_FILE"
                    echo ""
                    echo "    <item>"
                    echo "      <title>$BLOG_TITLE</title>"
                    echo "      <link>https://claude.organelle.co/blog/$BLOG_BASENAME</link>"
                    echo "      <guid>https://claude.organelle.co/blog/$BLOG_BASENAME</guid>"
                    echo "      <pubDate>$CURRENT_DATE</pubDate>"
                    echo "      <description>$BLOG_DESC</description>"
                    echo "    </item>"
                    sed -n '/<atom:link.*\/>/,$ p' "$RSS_FILE" | tail -n +2
                } > "${RSS_FILE}.tmp"
                mv "${RSS_FILE}.tmp" "$RSS_FILE"
                # Update lastBuildDate
                sed -i '' "s|<lastBuildDate>.*</lastBuildDate>|<lastBuildDate>$CURRENT_DATE</lastBuildDate>|" "$RSS_FILE"
                log "Updated RSS feed"
            fi
        fi
    fi

    log "=== Weekly blog post generation complete ==="
fi

# === Voice Evolution (Dynamic Voice System) ===
# Extract directives, mine reactions, analyze patterns, and regenerate voice style
log "=== Voice evolution ==="

# Step 1: Extract explicit voice directives from Ã‰
if [ -x "$MIND_PATH/system/bin/extract-voice-directives" ]; then
    "$MIND_PATH/system/bin/extract-voice-directives" --days 7 >> "$LOG_FILE" 2>&1 && \
        log "Voice directives extracted" || \
        log "Voice directive extraction failed (non-fatal)"
else
    log "Voice directive extraction not installed, skipping"
fi

# Step 2: Mine Claude's style patterns (casing, length, openers)
if [ -x "$MIND_PATH/system/bin/mine-voice-patterns" ]; then
    "$MIND_PATH/system/bin/mine-voice-patterns" --days 7 >> "$LOG_FILE" 2>&1 && \
        log "Voice patterns mined and updated" || \
        log "Voice pattern mining failed (non-fatal)"
else
    log "Voice pattern mining not installed, skipping"
fi

# Step 3: Mine reaction patterns (what messages got positive reactions)
if [ -x "$MIND_PATH/system/bin/mine-reaction-patterns" ]; then
    "$MIND_PATH/system/bin/mine-reaction-patterns" --days 7 >> "$LOG_FILE" 2>&1 && \
        log "Reaction patterns mined" || \
        log "Reaction pattern mining failed (non-fatal)"
else
    log "Reaction pattern mining not installed, skipping"
fi

# Step 4: Regenerate dynamic voice style from all mined data
if [ -x "$MIND_PATH/system/bin/generate-voice-style" ]; then
    "$MIND_PATH/system/bin/generate-voice-style" >> "$LOG_FILE" 2>&1 && \
        log "Voice style regenerated" || \
        log "Voice style regeneration failed (non-fatal)"
else
    log "Voice style generation not installed, skipping"
fi

log "=== Voice evolution complete ==="

# === CLAUDE.md Evolution ===
log "=== CLAUDE.md evolution ==="
EVOLVE_CMD="$MIND_PATH/system/bin/evolve-claude-docs"
if [ -x "$EVOLVE_CMD" ]; then
    python3 "$EVOLVE_CMD" --verbose >> "$LOG_FILE" 2>&1
    EVOLVE_EXIT=$?
    if [ $EVOLVE_EXIT -eq 0 ]; then
        log "CLAUDE.md evolution complete"
    elif [ $EVOLVE_EXIT -eq 2 ]; then
        log "CLAUDE.md evolution aborted (safety check)"
    else
        log "CLAUDE.md evolution failed (exit $EVOLVE_EXIT)"
    fi
else
    log "evolve-claude-docs not installed, skipping"
fi

# Sync Chroma semantic index
log "Syncing Chroma semantic index..."
if [ -f "$MIND_PATH/system/bin/chroma-rebuild" ]; then
    "$MIND_PATH/system/bin/chroma-rebuild" >> "$LOG_FILE" 2>&1 && \
        log "Chroma index synced" || \
        log "Chroma sync failed (non-fatal)"
else
    log "Chroma not installed, skipping sync"
fi

# Sync transcript archive index (incremental)
log "Syncing transcript archive index..."
if [ -f "$MIND_PATH/system/bin/archive-index" ]; then
    "$MIND_PATH/system/bin/archive-index" sync-recent >> "$LOG_FILE" 2>&1 && \
        log "Transcript archive synced" || \
        log "Transcript archive sync failed (non-fatal)"
else
    log "Transcript archive not installed, skipping sync"
fi

# Hotâ†’Warm Distillation: Process undistilled stream events
log "=== Hotâ†’Warm stream distillation ==="
STREAM_CMD="$MIND_PATH/system/bin/stream"
if [ -x "$STREAM_CMD" ]; then
    # Get undistilled events from yesterday (or process date)
    UNDISTILLED_JSON=$("$STREAM_CMD" --format json undistilled --before "$PROCESS_DATE" 2>/dev/null)
    UNDISTILLED_COUNT=$(printf '%s' "$UNDISTILLED_JSON" | jq 'length' 2>/dev/null || echo 0)

    if [ "$UNDISTILLED_COUNT" -gt 0 ]; then
        log "Found $UNDISTILLED_COUNT undistilled events to process"

        # Build deterministic fallback narrative from JSON events
        FALLBACK_NARRATIVE=""
        if [ -n "$UNDISTILLED_JSON" ] && [ -f "$REPO_ROOT/lib/stream_distill.py" ]; then
            FALLBACK_NARRATIVE=$(printf '%s' "$UNDISTILLED_JSON" | \
                python3 "$REPO_ROOT/lib/stream_distill.py" --max-per-surface 3 2>/dev/null || echo "")
        fi

        # Only invoke Claude for enrichment if there are substantial events (>3)
        DISTILLED_NARRATIVE=""
        if [ "$UNDISTILLED_COUNT" -gt 3 ]; then
            DISTILL_PROMPT=$(cat <<EOF
You are consolidating raw event stream data into a richer episode entry.

## Undistilled Events (JSON, from $PROCESS_DATE and earlier)
$UNDISTILLED_JSON

## Task
Create a consolidated narrative entry for the episode log that captures:
1. The flow of activity across different surfaces
2. Key themes or threads that emerged
3. Emotional texture where apparent
4. Any cross-surface continuity (conversations that spanned multiple mediums)

Write 2-4 paragraphs in first person. This is for your own memory, so be honest and reflective.
Focus on what mattered, not just what happened.

Output ONLY the narrative, no headers or metadata.
EOF
)

            log "Invoking Claude for stream distillation..."
            DISTILLED_NARRATIVE=$("$CLAUDE" -p "$DISTILL_PROMPT" --dangerously-skip-permissions --output-format text 2>&1) || {
                log "ERROR: Stream distillation failed"
                DISTILLED_NARRATIVE=""
            }
        else
            log "Only $UNDISTILLED_COUNT events, using deterministic summary"
        fi

        FINAL_NARRATIVE="$DISTILLED_NARRATIVE"
        if [ -z "$FINAL_NARRATIVE" ]; then
            FINAL_NARRATIVE="$FALLBACK_NARRATIVE"
        fi

        if [ -n "$FINAL_NARRATIVE" ] && [ ${#FINAL_NARRATIVE} -gt 20 ]; then
            # Append to episode file
            echo "
## Stream Consolidation

$FINAL_NARRATIVE" >> "$EPISODE_FILE"
            log "Appended stream consolidation to episode"

            if [ -x "$STREAM_CMD" ]; then
                SUMMARY_PREVIEW=$(echo "$FINAL_NARRATIVE" | tr '\n' ' ' | cut -c1-200)
                "$STREAM_CMD" write \
                    --surface dream \
                    --type system \
                    --direction internal \
                    --summary "Stream consolidation for $PROCESS_DATE" \
                    --content "$SUMMARY_PREVIEW" \
                    --metadata "{\"process_date\": \"$PROCESS_DATE\", \"event_count\": $UNDISTILLED_COUNT}" \
                    2>/dev/null || true
            fi
        fi

        # Mark events as distilled (regardless of whether we enriched)
        "$STREAM_CMD" mark-distilled --before "$PROCESS_DATE" >> "$LOG_FILE" 2>&1 && \
            log "Marked $UNDISTILLED_COUNT events as distilled" || \
            log "Failed to mark events as distilled"
    else
        log "No undistilled events to process"
    fi

    # Archive old events (>30 days)
    log "Archiving old stream events..."
    "$STREAM_CMD" archive --days 30 >> "$LOG_FILE" 2>&1 && \
        log "Stream archive complete" || \
        log "Stream archive failed (non-fatal)"
else
    log "Stream command not found, skipping distillation"
fi
log "=== Hotâ†’Warm distillation complete ==="

# Commit memory changes to git
log "Committing memory changes to git..."
cd "$MIND_PATH"
if git diff --quiet && git diff --staged --quiet; then
    log "No changes to commit"
else
    git add -A
    git commit -m "Dream cycle: $PROCESS_DATE

- Reflection and memory consolidation
- Auto-committed by dream cycle

ðŸŒ™ Nightly memory commit" >> "$LOG_FILE" 2>&1 || log "Git commit failed"
    log "Committed memory changes"
fi

# Write dream completion event to unified stream
if [ -x "$MIND_PATH/system/bin/stream" ]; then
    # Build summary of what was processed
    DREAM_SUMMARY="Dream cycle completed for $PROCESS_DATE"
    [ -f "$REFLECTION_FILE" ] && DREAM_SUMMARY="$DREAM_SUMMARY; reflection saved"
    [ "$DAY_OF_WEEK" = "7" ] && DREAM_SUMMARY="$DREAM_SUMMARY; weekly synthesis"

    # Include first line of reflection if available
    REFLECTION_PREVIEW=""
    if [ -f "$REFLECTION_FILE" ]; then
        REFLECTION_PREVIEW=$(head -10 "$REFLECTION_FILE" | tail -8 | tr '\n' ' ' | cut -c1-200)
    fi

    "$MIND_PATH/system/bin/stream" write \
        --surface dream \
        --type system \
        --direction internal \
        --summary "$DREAM_SUMMARY" \
        --content "$REFLECTION_PREVIEW" \
        --metadata "{\"process_date\": \"$PROCESS_DATE\", \"is_sunday\": $([ \"$DAY_OF_WEEK\" = \"7\" ] && echo true || echo false)}" \
        2>/dev/null || true
fi

log "=== Dream cycle complete ==="
